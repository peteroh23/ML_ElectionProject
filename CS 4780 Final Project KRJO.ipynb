{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "CS 4780 Final Project KRJO.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixW8M6IQ4zWY"
      },
      "source": [
        "<h2>CS 4780/5780 Final Project: </h2>\n",
        "<h3>Election Result Prediction for US Counties</h3>\n",
        "\n",
        "Names and NetIDs for your group members:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aa2ms5Ay4zWY"
      },
      "source": [
        "<h3>Introduction:</h3>\n",
        "\n",
        "<p> The final project is about conducting a real-world machine learning project on your own, with everything that is involved. Unlike in the programming projects 1-5, where we gave you all the scaffolding and you just filled in the blanks, you now start from scratch. The programming project provide templates for how to do this, and the most recent video lectures summarize some of the tricks you will need (e.g. feature normalization, feature construction). So, this final project brings realism to how you will use machine learning in the real world.  </p>\n",
        "\n",
        "The task you will work on is forecasting election results. Economic and sociological factors have been widely used when making predictions on the voting results of US elections. Economic and sociological factors vary a lot among counties in the United States. In addition, as you may observe from the election map of recent elections, neighbor counties show similar patterns in terms of the voting results. In this project you will bring the power of machine learning to make predictions for the county-level election results using Economic and sociological factors and the geographic structure of US counties. </p>\n",
        "<p>\n",
        "\n",
        "<h3>Your Task:</h3>\n",
        "Plase read the project description PDF file carefully and make sure you write your code and answers to all the questions in this Jupyter Notebook. Your answers to the questions are a large portion of your grade for this final project. Please import the packages in this notebook and cite any references you used as mentioned in the project description. You need to print this entire Jupyter Notebook as a PDF file and submit to Gradescope and also submit the ipynb runnable version to Canvas for us to run.\n",
        "\n",
        "<h3>Due Date:</h3>\n",
        "The final project dataset and template jupyter notebook will be due on <strong>December 15th</strong> . Note that <strong>no late submissions will be accepted</strong>  and you cannot use any of your unused slip days before.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3ER7qkY4zWY"
      },
      "source": [
        "![image.png; width=\"100\";](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGQz5-nO4zWZ"
      },
      "source": [
        "<h2>Part 1: Basics</h2><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svdidb3o4zWZ"
      },
      "source": [
        "<h3>1.1 Import:</h3><p>\n",
        "Please import necessary packages to use. Note that learning and using packages are recommended but not required for this project. Some official tutorial for suggested packacges includes:\n",
        "    \n",
        "https://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
        "    \n",
        "https://pytorch.org/tutorials/\n",
        "    \n",
        "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8VIF2F3f4zWZ"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "# TODO"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om_m3DKm4zWa"
      },
      "source": [
        "<h3>1.2 Weighted Accuracy:</h3><p>\n",
        "Since our dataset labels are heavily biased, you need to use the following function to compute weighted accuracy throughout your training and validation process and we use this for testing on Kaggle.\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd8CrgRG4zWa"
      },
      "source": [
        "def weighted_accuracy(pred, true):\n",
        "    assert(len(pred) == len(true))\n",
        "    num_labels = len(true)\n",
        "    num_pos = sum(true)\n",
        "    num_neg = num_labels - num_pos\n",
        "    frac_pos = num_pos/num_labels\n",
        "    weight_pos = 1/frac_pos\n",
        "    weight_neg = 1/(1-frac_pos)\n",
        "    num_pos_correct = 0\n",
        "    num_neg_correct = 0\n",
        "    for pred_i, true_i in zip(pred, true):\n",
        "        num_pos_correct += (pred_i == true_i and true_i == 1)\n",
        "        num_neg_correct += (pred_i == true_i and true_i == 0)\n",
        "    weighted_accuracy = ((weight_pos * num_pos_correct) \n",
        "                         + (weight_neg * num_neg_correct))/((weight_pos * num_pos) + (weight_neg * num_neg))\n",
        "    return weighted_accuracy"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSekpwQd4zWa"
      },
      "source": [
        "<h2>Part 2: Baseline Solution</h2><p>\n",
        "Note that your code should be commented well and in part 2.4 you can refer to your comments. (e.g. # Here is SVM, \n",
        "# Here is validation for SVM, etc). Also, we recommend that you do not to use 2012 dataset and the graph dataset to reach the baseline accuracy for 68% in this part, a basic solution with only 2016 dataset and reasonable model selection will be enough, it will be great if you explore thee graph and possibly 2012 dataset in Part 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVsv5-Z64zWa"
      },
      "source": [
        "<h3>2.1 Preprocessing and Feature Extraction:</h3><p>\n",
        "Given the training dataset and graph information, you need to correctly preprocess the dataset (e.g. feature normalization). For baseline solution in this part, you might not need to introduce extra features to reach the baseline test accuracy.\n",
        "<p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lp62UU8a4zWa"
      },
      "source": [
        "# You may change this but we suggest loading data with the following code and you may need to change\n",
        "# datatypes and do necessary data transformation after loading the raw data to the dataframe.\n",
        "dataset_train_path = \"train_2016.csv\"\n",
        "dataset_test_path = \"test_2016_no_label.csv\"\n",
        "df = pd.read_csv(dataset_train_path, sep=',',header=None,encoding='unicode_escape')\n",
        "df2 = pd.read_csv(dataset_test_path, sep=',',header=None,encoding='unicode_escape')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4R4CciP4zWa",
        "outputId": "321cc113-af9e-4e37-d319-0c7f4e50e37a"
      },
      "source": [
        "#Preprocessing Train Dataset\n",
        "#create a new column for labels\n",
        "df[10] = 0\n",
        "df[10][0] = 'Predictions'\n",
        "\n",
        "#fill in the new column: Label == 1 if DEM > GOP, Label == 0 otherwise\n",
        "for i in range(1, len(df)):\n",
        "    if (int(df.loc[i, 2])) > (int(df.loc[i, 3])): df.loc[i, 10] = 1\n",
        "\n",
        "#Change Columns names from # -> String\n",
        "for i in range(len(df.loc[0])):df = df.rename(columns= {i:df.loc[0][i]})\n",
        "\n",
        "#Remove unnecessary 0th row\n",
        "df = df.drop([0])\n",
        "\n",
        "#remove thousand comma\n",
        "df['MedianIncome']=df['MedianIncome'].str.replace(',','')\n",
        "\n",
        "#type conversions\n",
        "df = df.astype({'MedianIncome': int, 'MigraRate': float,'BirthRate': float,'DeathRate': float,'BachelorRate': float,'UnemploymentRate': float})"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "j7LVtxdC4zWb",
        "outputId": "ffa833d2-96d5-4ec7-8ed2-0fe62f8e574b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FIPS</th>\n",
              "      <th>County</th>\n",
              "      <th>DEM</th>\n",
              "      <th>GOP</th>\n",
              "      <th>MedianIncome</th>\n",
              "      <th>MigraRate</th>\n",
              "      <th>BirthRate</th>\n",
              "      <th>DeathRate</th>\n",
              "      <th>BachelorRate</th>\n",
              "      <th>UnemploymentRate</th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18019</td>\n",
              "      <td>Clark County, IN</td>\n",
              "      <td>18791</td>\n",
              "      <td>30012</td>\n",
              "      <td>51837</td>\n",
              "      <td>4.9</td>\n",
              "      <td>12.8</td>\n",
              "      <td>11.0</td>\n",
              "      <td>20.9</td>\n",
              "      <td>4.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6035</td>\n",
              "      <td>Lassen County, CA</td>\n",
              "      <td>2026</td>\n",
              "      <td>6533</td>\n",
              "      <td>49793</td>\n",
              "      <td>-18.4</td>\n",
              "      <td>9.2</td>\n",
              "      <td>6.3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40081</td>\n",
              "      <td>Lincoln County, OK</td>\n",
              "      <td>2423</td>\n",
              "      <td>10838</td>\n",
              "      <td>44914</td>\n",
              "      <td>-1.3</td>\n",
              "      <td>11.4</td>\n",
              "      <td>11.7</td>\n",
              "      <td>15.1</td>\n",
              "      <td>5.3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31153</td>\n",
              "      <td>Sarpy County, NE</td>\n",
              "      <td>27704</td>\n",
              "      <td>44649</td>\n",
              "      <td>74374</td>\n",
              "      <td>9.2</td>\n",
              "      <td>14.2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>40.1</td>\n",
              "      <td>2.9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>28055</td>\n",
              "      <td>Issaquena County, MS</td>\n",
              "      <td>395</td>\n",
              "      <td>298</td>\n",
              "      <td>26957</td>\n",
              "      <td>-12.8</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5.3</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    FIPS                County  ... UnemploymentRate Predictions\n",
              "1  18019      Clark County, IN  ...              4.2           0\n",
              "2   6035     Lassen County, CA  ...              6.9           0\n",
              "3  40081    Lincoln County, OK  ...              5.3           0\n",
              "4  31153      Sarpy County, NE  ...              2.9           0\n",
              "5  28055  Issaquena County, MS  ...             14.0           1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BIl3hOqr4zWb",
        "outputId": "95aebaa4-9ea3-46f9-fb89-8dab27fdc6fa"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FIPS</td>\n",
              "      <td>County</td>\n",
              "      <td>MedianIncome</td>\n",
              "      <td>MigraRate</td>\n",
              "      <td>BirthRate</td>\n",
              "      <td>DeathRate</td>\n",
              "      <td>BachelorRate</td>\n",
              "      <td>UnemploymentRate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17059</td>\n",
              "      <td>Gallatin County, IL</td>\n",
              "      <td>39,634</td>\n",
              "      <td>-10.6</td>\n",
              "      <td>10.8</td>\n",
              "      <td>12.5</td>\n",
              "      <td>9.9</td>\n",
              "      <td>7.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6103</td>\n",
              "      <td>Tehama County, CA</td>\n",
              "      <td>40,585</td>\n",
              "      <td>1.8</td>\n",
              "      <td>12.8</td>\n",
              "      <td>10.4</td>\n",
              "      <td>15.5</td>\n",
              "      <td>7.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42047</td>\n",
              "      <td>Elk County, PA</td>\n",
              "      <td>49,274</td>\n",
              "      <td>-9.3</td>\n",
              "      <td>9.7</td>\n",
              "      <td>13</td>\n",
              "      <td>18.6</td>\n",
              "      <td>5.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>47147</td>\n",
              "      <td>Robertson County, TN</td>\n",
              "      <td>58,487</td>\n",
              "      <td>7.4</td>\n",
              "      <td>12.7</td>\n",
              "      <td>9.7</td>\n",
              "      <td>18.6</td>\n",
              "      <td>4.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0                     1  ...             6                 7\n",
              "0   FIPS                County  ...  BachelorRate  UnemploymentRate\n",
              "1  17059   Gallatin County, IL  ...           9.9               7.6\n",
              "2   6103     Tehama County, CA  ...          15.5               7.1\n",
              "3  42047        Elk County, PA  ...          18.6               5.5\n",
              "4  47147  Robertson County, TN  ...          18.6               4.1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmNxRvF_4zWb"
      },
      "source": [
        "#Preprocessing for Test DataSet\n",
        "\n",
        "#Change Column names from # -> String\n",
        "for i in range(len(df2.loc[0])):df2 = df2.rename(columns= {i:df2.loc[0][i]})\n",
        "\n",
        "#Remove unnecessary 0th row\n",
        "df2 = df2.drop([0])\n",
        "\n",
        "#remove thousand comma\n",
        "df2['MedianIncome']=df2['MedianIncome'].str.replace(',','')\n",
        "\n",
        "#type conversions\n",
        "df2 = df2.astype({'MedianIncome': int, 'MigraRate': float,'BirthRate': float,'DeathRate': float,'BachelorRate': float,'UnemploymentRate': float})"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM7AYx_X4zWb"
      },
      "source": [
        "def normalize(df):\n",
        "    result = df.copy()\n",
        "    for feature_name in df.columns:\n",
        "        if (feature_name == 'MedianIncome' or feature_name == 'MigraRate' or feature_name == 'BirthRate' or feature_name == 'DeathRate' or feature_name == 'BachelorRate' or feature_name == 'UnemploymentRate'):\n",
        "            max_value = df[feature_name].max()\n",
        "            min_value = df[feature_name].min()\n",
        "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
        "    return result"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsRGycUS4zWb",
        "outputId": "617fd804-604f-4e25-8ed9-1e177a40bd3c"
      },
      "source": [
        "df_train = normalize(df)\n",
        "df_test = normalize(df2)\n",
        "print(df_train)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       FIPS                  County  ... UnemploymentRate Predictions\n",
            "1     18019        Clark County, IN  ...         0.111607           0\n",
            "2      6035       Lassen County, CA  ...         0.232143           0\n",
            "3     40081      Lincoln County, OK  ...         0.160714           0\n",
            "4     31153        Sarpy County, NE  ...         0.053571           0\n",
            "5     28055    Issaquena County, MS  ...         0.549107           1\n",
            "...     ...                     ...  ...              ...         ...\n",
            "1551  36009  Cattaraugus County, NY  ...         0.191964           0\n",
            "1552  55031      Douglas County, WI  ...         0.156250           1\n",
            "1553  27065      Kanabec County, MN  ...         0.214286           0\n",
            "1554  17139     Moultrie County, IL  ...         0.129464           0\n",
            "1555  20185     Stafford County, KS  ...         0.089286           0\n",
            "\n",
            "[1555 rows x 11 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh06s8r_4zWb"
      },
      "source": [
        "<h3>2.2 Use At Least Two Training Algorithms from class:</h3><p>\n",
        "You need to use at least two training algorithms from class. You can use your code from previous projects or any packages you imported in part 1.1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nM56DD4d4zWb"
      },
      "source": [
        "#More packages for Algorithms:\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYEqJmKI4zWb"
      },
      "source": [
        "# Make sure you comment your code clearly and you may refer to these comments in the part 2.4\n",
        "# TODO\n",
        "# perceptron object with the parameters: 60 iterations (epochs) over the data, and a learning rate of 0.15\n",
        "ppn = Perceptron(max_iter=60, eta0=0.15, random_state=0)\n",
        "\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htl-o-o24zWb"
      },
      "source": [
        "<h3>2.3 Training, Validation and Model Selection:</h3><p>\n",
        "You need to split your data to a training set and validation set or performing a cross-validation for model selection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8nCCE1Ig4zWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46ce755c-2a59-407d-844b-7838b47a4dd5"
      },
      "source": [
        "# Splitting training data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_train.drop(columns = ['DEM', 'GOP','County', 'Predictions', 'FIPS']), df_train['Predictions'], test_size=0.3)\n",
        "y_train=y_train.astype('int')\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "ppn.fit(X_train, y_train)\n",
        "knn.fit(X_train, y_train)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aDkZg4A4zWb"
      },
      "source": [
        "#Predictions made from Perceptron\n",
        "y_pred_ppn = ppn.predict(X_test)\n",
        "#Predictions made from KNN\n",
        "y_pred_knn = knn.predict(X_test)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "SjXB1YlQ4zWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed8395e-9b16-4463-b2dd-e6d48feba74c"
      },
      "source": [
        "print(weighted_accuracy(y_pred_ppn, y_test))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7610386259767064\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgqBGIVt4zWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bbff5e-088d-42eb-bc96-35a314f67c43"
      },
      "source": [
        "print(weighted_accuracy(y_pred_knn, y_test))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7225969335102462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CGA54eG4zWb"
      },
      "source": [
        "<h3>2.4 Explanation in Words:</h3><p>\n",
        "    You need to answer the following questions in the markdown cell after this cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgloexbA4zWb"
      },
      "source": [
        "2.4.1 How did you preprocess the dataset and features?\n",
        "\n",
        "**One of the things we did to preprocess our dataset and features was adding a column \"Predictions\" which was a binary label of 0 if a county was Republican and 1 if a county was Democrat. This allowed us to more easily train our model, according to the binary classification of each county in the training set. Additionally, we removed all commas from numbers in the dataset and casted all rows in the dataset to make sure each feature was of the correct type. We also removed the first row of the datasets which had each column name and moved this up so that the dataset's column names were the actual column name strings as opposed to column indices. This made accessing each column much simpler.**\n",
        "\n",
        "2.4.2 Which two learning methods from class did you choose and why did you made the choices?\n",
        "\n",
        "**We chose to use KNN and the Perceptron learning methods, both of which are supervised learning approaches. We went with KNN because of its simplicity and we believed that it was likely that counties that were closer to each other (by distance) when considering characteristic dimensions such as unemployment rate and median income, would probably vote similarly. KNN takes this into account by selecting the label of the closest neighbor counties. We also chose to try the Perceptron learning method, primarily because of its ease of implementation. We knew that Perceptrons are only successful when the data is linearly separable, so we felt that trying this approach would tell us whether this was the case or not.**\n",
        "\n",
        "2.4.3 How did you do the model selection?\n",
        "\n",
        "2.4.4 Does the test performance reach a given baseline 68% performance? (Please include a screenshot of Kaggle Submission)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njigSj7V4zWb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj_pSKHO4zWb"
      },
      "source": [
        "<h2>Part 3: Creative Solution</h2><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwcS2IBo4zWb"
      },
      "source": [
        "<h3>3.1 Open-ended Code:</h3><p>\n",
        "You may follow the steps in part 2 again but making innovative changes like creating new features, using new training algorithms, etc. Make sure you explain everything clearly in part 3.2. Note that reaching the 75% creative baseline is only a small portion of this part. Any creative ideas will receive most points as long as they are reasonable and clearly explained."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ-U5G-E4zWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97af9009-89d1-479a-f37e-a4946f418291"
      },
      "source": [
        "# Make sure you comment your code clearly and you may refer to these comments in the part 3.2\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler # maybe add this to preprocessing step\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "\n",
        "# C_range = np.logspace(-2, 10, 5)\n",
        "# gamma_range = np.logspace(-9, 3, 5)\n",
        "# param_grid = dict(gamma=gamma_range, C=C_range)\n",
        "# grid = GridSearchCV(SVC(), param_grid=param_grid)\n",
        "# grid.fit(X_train_scaled, y_train)\n",
        "\n",
        "params = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "rbf_svm = SVC(gamma='auto')\n",
        "grid = GridSearchCV(rbf_svm, params)\n",
        "\n",
        "grid.fit(X_train_scaled, y_train)\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
              "                           class_weight=None, coef0=0.0,\n",
              "                           decision_function_shape='ovr', degree=3,\n",
              "                           gamma='auto', kernel='rbf', max_iter=-1,\n",
              "                           probability=False, random_state=None, shrinking=True,\n",
              "                           tol=0.001, verbose=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNOzGf7cIB2j"
      },
      "source": [
        "# Predictions made by RBF SVM approach\n",
        "y_pred_svm = grid.predict(X_test_scaled)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCwrPbpUIRRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efe76e71-3323-402f-8e75-e56615520b76"
      },
      "source": [
        "print(weighted_accuracy(y_pred_svm, y_test))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6847449506118237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EprFylw54zWb"
      },
      "source": [
        "<h3>3.2 Explanation in Words:</h3><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSk2WuVa4zWb"
      },
      "source": [
        "You need to answer the following questions in a markdown cell after this cell:\n",
        "\n",
        "3.2.1 How much did you manage to improve performance on the test set compared to part 2? Did you reach the 75% accuracy for the test in Kaggle? (Please include a screenshot of Kaggle Submission)\n",
        "\n",
        "3.2.2 Please explain in detail how you achieved this and what you did specifically and why you tried this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGzKk3Wd4zWb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbStTyMc4zWb"
      },
      "source": [
        "<h2>Part 4: Kaggle Submission</h2><p>\n",
        "You need to generate a prediction CSV using the following cell from your trained model and submit the direct output of your code to Kaggle. The CSV shall contain TWO column named exactly \"FIPS\" and \"Result\" and 1555 total rows excluding the column names, \"FIPS\" column shall contain FIPS of counties with same order as in the test_2016_no_label.csv while \"Result\" column shall contain the 0 or 1 prdicaitons for corresponding columns. A sample predication file can be downloaded from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USQHWJdf4zWb"
      },
      "source": [
        "# TODO\n",
        "\n",
        "# You may use pandas to generate a dataframe with FIPS and your predictions first \n",
        "# and then use to_csv to generate a CSV file."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsdvTfqr4zWb"
      },
      "source": [
        "<h2>Part 5: Resources and Literature Used</h2><p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NWMov3a4zWb"
      },
      "source": [
        ""
      ]
    }
  ]
}